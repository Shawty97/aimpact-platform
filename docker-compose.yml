version: '3.8'

services:
  # Backend API service
  backend:
    build:
      context: .
      dockerfile: ./Dockerfile.dev
    volumes:
      - ./backend:/app
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=development
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/aimpact
      - REDIS_URL=redis://redis:6379/0
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - JWT_SECRET=${JWT_SECRET:-devsecretkey}
      - JWT_EXPIRE=86400
    depends_on:
      - db
      - redis
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # Dashboard frontend
  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile.dev
    volumes:
      - ./dashboard:/app
      - /app/node_modules
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - NEXT_PUBLIC_API_URL=http://localhost:8000
    depends_on:
      - backend

  # Database
  db:
    image: postgres:15-alpine
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_DB=aimpact
    ports:
      - "5432:5432"

  # Redis for caching and message broker
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:v2.44.0
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    depends_on:
      - backend

  # Grafana for visualization
  grafana:
    image: grafana/grafana:10.0.3
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3001:3000"
    depends_on:
      - prometheus

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

version: '3.8'

services:
  # Core API Application
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./:/app
      - ./models:/app/models
    depends_on:
      - postgres
      - redis
      - ollama
      - workflow-engine
      - voice-service
      - llm-orchestrator
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/aimpact
      - VECTOR_DB_URL=postgresql://postgres:postgres@postgres:5432/aimpact
      - VECTOR_DB_TYPE=postgres
      - REDIS_URL=redis://redis:6379/0
      - DEFAULT_LLM_PROVIDER=local
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=mistral
      - LOCAL_LLM_MODEL=mistral-7b-instruct
      - VOICE_ENGINE_TYPE=coqui
      - SPEECH_RECOGNITION_PROVIDER=vosk
      - TTS_MODEL_PATH=/app/models/tts/coqui
      - STT_MODEL_PATH=/app/models/stt/vosk
      - USE_LOCAL_TTS=true
      - USE_LOCAL_STT=true
      - AGENT_STORE_ENABLED=true
      - KNOWLEDGE_BUILDER_ENABLED=true
      - WORKFLOW_ENGINE_URL=http://workflow-engine:8050/api
      - VOICE_SERVICE_URL=http://voice-service:8060/api
      - LLM_ORCHESTRATOR_URL=http://llm-orchestrator:8070/api
      - ENVIRONMENT=development
      - LOG_LEVEL=INFO
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Database with Vector Support
  postgres:
    image: ankane/pgvector:latest
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=aimpact
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Redis for Caching and Pub/Sub
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  # Local LLM Service
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_MODELS=mistral,llama2,llama2-uncensored
    command: sh -c "ollama pull mistral && ollama pull llama2 && ollama pull llama2-uncensored && ollama serve"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: all
    restart: unless-stopped

  # Advanced Workflow Engine (Better than Artisan.co)
  workflow-engine:
    build:
      context: ./services/workflow-engine
      dockerfile: Dockerfile
    ports:
      - "8050:8050"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/aimpact
      - REDIS_URL=redis://redis:6379/1
      - LLM_ORCHESTRATOR_URL=http://llm-orchestrator:8070/api
      - VOICE_SERVICE_URL=http://voice-service:8060/api
      - ENABLE_A_B_TESTING=true
      - ENABLE_COMPLEX_BRANCHING=true
      - ENABLE_FEEDBACK_LOOPS=true
      - ENABLE_AUTOPILOT=true
      - ENABLE_WORKFLOW_TEMPLATES=true
    volumes:
      - ./services/workflow-engine:/app
      - workflow_data:/app/data
    depends_on:
      - postgres
      - redis
    restart: unless-stopped

  # Voice Processing Service (Better than Vapi.ai)
  voice-service:
    build:
      context: ./services/voice-service
      dockerfile: Dockerfile
    ports:
      - "8060:8060"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/aimpact
      - REDIS_URL=redis://redis:6379/2
      - TTS_MODEL_PATH=/app/models/tts/coqui
      - STT_MODEL_PATH=/app/models/stt/vosk
      - ENABLE_EMOTION_DETECTION=true
      - ENABLE_CULTURAL_CONTEXT=true
      - ENABLE_VOICE_CLONING=true
      - ENABLE_MULTILINGUAL=true
      - ENABLE_REAL_TIME_PROCESSING=true
    volumes:
      - ./services/voice-service:/app
      - ./models:/app/models
      - voice_data:/app/data
    depends_on:
      - postgres
      - redis
    restart: unless-stopped

  # LLM Orchestrator (Multi-LLM Support)
  llm-orchestrator:
    build:
      context: ./services/llm-orchestrator
      dockerfile: Dockerfile
    ports:
      - "8070:8070"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/aimpact
      - REDIS_URL=redis://redis:6379/3
      - OLLAMA_URL=http://ollama:11434
      - ENABLE_PROVIDER_ROUTING=true
      - ENABLE_COST_OPTIMIZATION=true
      - ENABLE_MODEL_FALLBACKS=true
      - ENABLE_PERFORMANCE_TRACKING=true
      - ENABLE_CONTEXT_MANAGEMENT=true
      - SUPPORTED_PROVIDERS=ollama,openai,anthropic,cohere,localai
    volumes:
      - ./services/llm-orchestrator:/app
      - llm_data:/app/data
    depends_on:
      - postgres
      - redis
      - ollama
    restart: unless-stopped

  # Knowledge Auto-Builder
  knowledge-builder:
    build:
      context: ./services/knowledge-builder
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/aimpact
      - VECTOR_DB_URL=postgresql://postgres:postgres@postgres:5432/aimpact
      - REDIS_URL=redis://redis:6379/4
      - LLM_ORCHESTRATOR_URL=http://llm-orchestrator:8070/api
      - ENABLE_DOCUMENT_PROCESSING=true
      - ENABLE_EMBEDDING_GENERATION=true
      - ENABLE_AUTO_CATEGORIZATION=true
      - ENABLE_KNOWLEDGE_GRAPH=true
    volumes:
      - ./services/knowledge-builder:/app
      - knowledge_data:/app/data
    depends_on:
      - postgres
      - redis
      - llm-orchestrator
    restart: unless-stopped

  # Agent Store (Marketplace)
  agent-store:
    build:
      context: ./services/agent-store
      dockerfile: Dockerfile
    ports:
      - "8090:8090"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/aimpact
      - REDIS_URL=redis://redis:6379/5
      - WORKFLOW_ENGINE_URL=http://workflow-engine:8050/api
      - LLM_ORCHESTRATOR_URL=http://llm-orchestrator:8070

